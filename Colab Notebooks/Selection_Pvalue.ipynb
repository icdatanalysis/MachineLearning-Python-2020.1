{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Selection_Pvalue.ipynb","provenance":[{"file_id":"1FD9ObNcfVHWUvKfX2Nk-GSDXFeYs-qhz","timestamp":1574183344084},{"file_id":"1LSoV8tF08t0e8Rb-1KwmgH0V19ppBruz","timestamp":1573036409693}],"collapsed_sections":["UC8TV3Z2lW2B"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EB3dPPlgQeVt","colab_type":"text"},"source":["# Processo de Seleção de Variáveis Usando P-Value."]},{"cell_type":"markdown","metadata":{"id":"TsV0SiuwpZ7i","colab_type":"text"},"source":["### Importando libs e funções:"]},{"cell_type":"markdown","metadata":{"id":"k6l8c0olEHpN","colab_type":"text"},"source":["Importando libs"]},{"cell_type":"code","metadata":{"id":"i7FF5Glb_NrK","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import random\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler \n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7RydZ0qEIl4","colab_type":"text"},"source":["Importando funções"]},{"cell_type":"code","metadata":{"id":"KxneBJZUEIz4","colab_type":"code","colab":{}},"source":["# Função de escalonamento\n","def feature_scaling(data):\n","    sc = StandardScaler()\n","    return sc.fit_transform(data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QaGBc_KwpeVt","colab_type":"text"},"source":["### Etapa de exploração e tratamento dos **dados**"]},{"cell_type":"markdown","metadata":{"id":"ZfESkLx0EjB8","colab_type":"text"},"source":["Importando o dataset do nosso estudo. O objetivo do modelo de regressão será de predizer o preço das casas de acordo com diferentes atributos como: localização, área do lote, garagem, etc.\n","\n","Fonte: [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"]},{"cell_type":"code","metadata":{"id":"Yq6eIh3NJnuN","colab_type":"code","colab":{}},"source":["df = pd.read_csv('https://raw.githubusercontent.com/r4phael/ml-course/master/data/pricing_houses.csv')\n","\n","#Selecionando algumas features dos dados para uma melhor visualização do problema\n","df = df.loc[:, ['LotArea', 'PoolArea', 'GarageArea', 'OverallCond','YearBuilt', 'YrSold', 'Fireplaces',\n","                'SalePrice']]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-LzSHX1Jpg1","colab_type":"text"},"source":["Descrevendo o dataset"]},{"cell_type":"code","metadata":{"id":"hpLEK45DJomb","colab_type":"code","outputId":"55299b68-10db-467a-a36d-a41ea37f2455","executionInfo":{"status":"ok","timestamp":1575121189764,"user_tz":180,"elapsed":1124,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["df.describe()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YrSold</th>\n","      <th>Fireplaces</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>10516.828082</td>\n","      <td>2.758904</td>\n","      <td>472.980137</td>\n","      <td>5.575342</td>\n","      <td>1971.267808</td>\n","      <td>2007.815753</td>\n","      <td>0.613014</td>\n","      <td>180921.195890</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9981.264932</td>\n","      <td>40.177307</td>\n","      <td>213.804841</td>\n","      <td>1.112799</td>\n","      <td>30.202904</td>\n","      <td>1.328095</td>\n","      <td>0.644666</td>\n","      <td>79442.502883</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1300.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1872.000000</td>\n","      <td>2006.000000</td>\n","      <td>0.000000</td>\n","      <td>34900.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>7553.500000</td>\n","      <td>0.000000</td>\n","      <td>334.500000</td>\n","      <td>5.000000</td>\n","      <td>1954.000000</td>\n","      <td>2007.000000</td>\n","      <td>0.000000</td>\n","      <td>129975.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>9478.500000</td>\n","      <td>0.000000</td>\n","      <td>480.000000</td>\n","      <td>5.000000</td>\n","      <td>1973.000000</td>\n","      <td>2008.000000</td>\n","      <td>1.000000</td>\n","      <td>163000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>11601.500000</td>\n","      <td>0.000000</td>\n","      <td>576.000000</td>\n","      <td>6.000000</td>\n","      <td>2000.000000</td>\n","      <td>2009.000000</td>\n","      <td>1.000000</td>\n","      <td>214000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>215245.000000</td>\n","      <td>738.000000</td>\n","      <td>1418.000000</td>\n","      <td>9.000000</td>\n","      <td>2010.000000</td>\n","      <td>2010.000000</td>\n","      <td>3.000000</td>\n","      <td>755000.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             LotArea     PoolArea  ...   Fireplaces      SalePrice\n","count    1460.000000  1460.000000  ...  1460.000000    1460.000000\n","mean    10516.828082     2.758904  ...     0.613014  180921.195890\n","std      9981.264932    40.177307  ...     0.644666   79442.502883\n","min      1300.000000     0.000000  ...     0.000000   34900.000000\n","25%      7553.500000     0.000000  ...     0.000000  129975.000000\n","50%      9478.500000     0.000000  ...     1.000000  163000.000000\n","75%     11601.500000     0.000000  ...     1.000000  214000.000000\n","max    215245.000000   738.000000  ...     3.000000  755000.000000\n","\n","[8 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"tgh2pe9lJtr6","colab_type":"text"},"source":["Visualizando o dataset"]},{"cell_type":"code","metadata":{"id":"EvY28fJdJxey","colab_type":"code","outputId":"964637d5-b89f-47bc-e7b5-d6a4480c19fa","executionInfo":{"status":"ok","timestamp":1575121193022,"user_tz":180,"elapsed":1317,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df.head(5)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YrSold</th>\n","      <th>Fireplaces</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>2008</td>\n","      <td>0</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>2007</td>\n","      <td>1</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>2006</td>\n","      <td>1</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  ...  YrSold  Fireplaces  SalePrice\n","0     8450         0         548  ...    2008           0     208500\n","1     9600         0         460  ...    2007           1     181500\n","2    11250         0         608  ...    2008           1     223500\n","3     9550         0         642  ...    2006           1     140000\n","4    14260         0         836  ...    2008           1     250000\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"jiMAqVghJylz","colab_type":"text"},"source":["Preenchendo os valores númericos nulos (NA) com a mediana."]},{"cell_type":"code","metadata":{"id":"KFDodNK4JzlR","colab_type":"code","outputId":"feda1b1c-43fd-464d-9617-7445f73f96e2","executionInfo":{"status":"ok","timestamp":1575121194223,"user_tz":180,"elapsed":1221,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["df = df.fillna(df.median())\n","\n","df.head(5)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>PoolArea</th>\n","      <th>GarageArea</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YrSold</th>\n","      <th>Fireplaces</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>5</td>\n","      <td>2003</td>\n","      <td>2008</td>\n","      <td>0</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>0</td>\n","      <td>460</td>\n","      <td>8</td>\n","      <td>1976</td>\n","      <td>2007</td>\n","      <td>1</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>0</td>\n","      <td>608</td>\n","      <td>5</td>\n","      <td>2001</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>0</td>\n","      <td>642</td>\n","      <td>5</td>\n","      <td>1915</td>\n","      <td>2006</td>\n","      <td>1</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>0</td>\n","      <td>836</td>\n","      <td>5</td>\n","      <td>2000</td>\n","      <td>2008</td>\n","      <td>1</td>\n","      <td>250000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   LotArea  PoolArea  GarageArea  ...  YrSold  Fireplaces  SalePrice\n","0     8450         0         548  ...    2008           0     208500\n","1     9600         0         460  ...    2007           1     181500\n","2    11250         0         608  ...    2008           1     223500\n","3     9550         0         642  ...    2006           1     140000\n","4    14260         0         836  ...    2008           1     250000\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UC8TV3Z2lW2B"},"source":["## Forward Elimination\n"]},{"cell_type":"markdown","metadata":{"id":"cPd_vjDamxMl","colab_type":"text"},"source":["### Etapa de Seleção e Tratamento dos Dados"]},{"cell_type":"markdown","metadata":{"id":"oZBk769mlh_u","colab_type":"text"},"source":["Definindo as variáveis indepedentes e dependentes, normalição das features e divisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"id":"Emt4_DJMliIu","colab_type":"code","colab":{}},"source":["X = df[df.columns[~df.columns.isin(['SalePrice'])]].values\n","y = df['SalePrice'].values.reshape(-1,1)\n","\n","# Normalização das features:\n","X = feature_scaling(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_AaV4oLm6G7","colab_type":"text"},"source":["### Realizando o Processo de Foward Elimination\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JEP6wygGlW2C"},"source":["Realizando o processo de Forward Elimination. Esse processo é realizado através de uma análise incremental da contribuição das features ao modelo final. Portanto, a cada iteração é adicionada uma feature que deverá ser analisada seu impacto no modelo através do *p-value*."]},{"cell_type":"markdown","metadata":{"id":"mbHPIp-nqwQJ","colab_type":"text"},"source":["Primeiro, será inserido uma coluna preenchida com valores 1 no começo da matriz de feature para que seja realizado os cálculos necessários. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g7fedOQflW2C","colab":{}},"source":["X = np.append(arr = np.ones((1460,1)).astype(int), values = X, axis =1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T1lSrNMdqy0X","colab_type":"text"},"source":["Divisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"id":"VXv6nlErqy8V","colab_type":"code","outputId":"f51c1388-877d-4982-c17d-c14335443822","executionInfo":{"status":"ok","timestamp":1575121213636,"user_tz":180,"elapsed":1097,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Dividindo os dados\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","X_train[1:5,:5]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.        , -0.26857781, -0.06869175, -0.43503222,  1.28068524],\n","       [ 1.        , -0.1743691 , -0.06869175, -2.21296298,  1.28068524],\n","       [ 1.        , -0.33241925, -0.06869175, -1.09005935,  1.28068524],\n","       [ 1.        , -0.55290771, -0.06869175, -0.77190332,  0.38174271]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"D3AjKcRorTdm","colab_type":"text"},"source":["Adição da 1ª Feature (*LotArea* - Área do Lote):"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"3d04dd4b-3459-42b1-c25a-d6125d642423","executionInfo":{"status":"ok","timestamp":1575121220826,"user_tz":180,"elapsed":1203,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"id":"BUh57AsOlW2F","colab":{"base_uri":"https://localhost:8080/","height":444}},"source":["# Importando a package.\n","import statsmodels.regression.linear_model as sm\n","\n","X_opt = X_train[:, [0,1]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_train[:, [0,1]]).fit()\n","regressor_ols.summary()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.071</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.070</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   88.93</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Sat, 30 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>2.13e-20</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>13:40:20</td>     <th>  Log-Likelihood:    </th> <td> -14760.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.952e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1166</td>      <th>  BIC:               </th> <td>2.953e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.811e+05</td> <td> 2180.395</td> <td>   83.063</td> <td> 0.000</td> <td> 1.77e+05</td> <td> 1.85e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.907e+04</td> <td> 2022.624</td> <td>    9.430</td> <td> 0.000</td> <td> 1.51e+04</td> <td>  2.3e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>425.777</td> <th>  Durbin-Watson:     </th> <td>   2.049</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1973.518</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.657</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 8.437</td>  <th>  Cond. No.          </th> <td>    1.08</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.071\n","Model:                            OLS   Adj. R-squared:                  0.070\n","Method:                 Least Squares   F-statistic:                     88.93\n","Date:                Sat, 30 Nov 2019   Prob (F-statistic):           2.13e-20\n","Time:                        13:40:20   Log-Likelihood:                -14760.\n","No. Observations:                1168   AIC:                         2.952e+04\n","Df Residuals:                    1166   BIC:                         2.953e+04\n","Df Model:                           1                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.811e+05   2180.395     83.063      0.000    1.77e+05    1.85e+05\n","x1          1.907e+04   2022.624      9.430      0.000    1.51e+04     2.3e+04\n","==============================================================================\n","Omnibus:                      425.777   Durbin-Watson:                   2.049\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1973.518\n","Skew:                           1.657   Prob(JB):                         0.00\n","Kurtosis:                       8.437   Cond. No.                         1.08\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"U-RSW_bQlW2I"},"source":["Analisando os valores acima, vimos que as features X1(*LotArea* - Área do lote) possui um P-value significativo, ou seja, dentro do intervalo definido (SL = .05) .Portanto, deixamos a mesma e escolhemos outra feature para incrementar no modelo conforme o processo de Forward Elimination.  \n","\n","**Obs: Definimos um level de significância (SL) de .05 para que as features permaneçam no modelo (SL = .05).**"]},{"cell_type":"markdown","metadata":{"id":"drqbur2qsCJv","colab_type":"text"},"source":["Calculando os coeficientes com a adição da 2ª feature (*PoolArea* - Área da Piscina):\n"]},{"cell_type":"code","metadata":{"id":"aCAhwA5nsCSc","colab_type":"code","outputId":"a900fe24-6bd4-49c6-ef27-aaff96a15b9c","executionInfo":{"status":"ok","timestamp":1575036329694,"user_tz":180,"elapsed":1964,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Selecionando apenas as features de indice 0-const, 1-LotArea, 2-PoolArea\n","X_opt = X_train[:, [0,1,2]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.080</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.078</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   50.31</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Fri, 29 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.10e-21</td> \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>14:05:29</td>     <th>  Log-Likelihood:    </th> <td> -14754.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.951e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1165</td>      <th>  BIC:               </th> <td>2.953e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.811e+05</td> <td> 2171.175</td> <td>   83.405</td> <td> 0.000</td> <td> 1.77e+05</td> <td> 1.85e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>  1.85e+04</td> <td> 2021.631</td> <td>    9.149</td> <td> 0.000</td> <td> 1.45e+04</td> <td> 2.25e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 6952.4530</td> <td> 2102.250</td> <td>    3.307</td> <td> 0.001</td> <td> 2827.833</td> <td> 1.11e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>375.808</td> <th>  Durbin-Watson:     </th> <td>   2.045</td> \n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1345.385</td> \n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.540</td>  <th>  Prob(JB):          </th> <td>7.13e-293</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 7.261</td>  <th>  Cond. No.          </th> <td>    1.11</td> \n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.080\n","Model:                            OLS   Adj. R-squared:                  0.078\n","Method:                 Least Squares   F-statistic:                     50.31\n","Date:                Fri, 29 Nov 2019   Prob (F-statistic):           1.10e-21\n","Time:                        14:05:29   Log-Likelihood:                -14754.\n","No. Observations:                1168   AIC:                         2.951e+04\n","Df Residuals:                    1165   BIC:                         2.953e+04\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.811e+05   2171.175     83.405      0.000    1.77e+05    1.85e+05\n","x1           1.85e+04   2021.631      9.149      0.000    1.45e+04    2.25e+04\n","x2          6952.4530   2102.250      3.307      0.001    2827.833    1.11e+04\n","==============================================================================\n","Omnibus:                      375.808   Durbin-Watson:                   2.045\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1345.385\n","Skew:                           1.540   Prob(JB):                    7.13e-293\n","Kurtosis:                       7.261   Cond. No.                         1.11\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":77}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"H8BuJW08nmfo"},"source":["Analisando os valores acima, vimos que as features X1 e X2 possuem um P-value significativo, ou seja, dentro do intervalo definido (SL = .05) .Portanto, deixamos elas e escolhemos outra feature para incrementar no modelo conforme o processo de Forward Elimination. "]},{"cell_type":"markdown","metadata":{"id":"YPd6r9rAnyJq","colab_type":"text"},"source":["Calculando os coeficientes com a adição da 3ª feature (*GarageArea* - Área da Garagem):\n"]},{"cell_type":"code","metadata":{"id":"rmp5XGlenykP","colab_type":"code","outputId":"33d379a5-96bd-49e1-affe-b38370decf0f","executionInfo":{"status":"ok","timestamp":1575036329694,"user_tz":180,"elapsed":1956,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Selecionando apenas as features de indice 0-const, 1-LotArea, 2-PoolArea, 3-GarageArea\n","X_opt = X_train[:, [0,1,2,3]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.417</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.416</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   277.7</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Fri, 29 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>6.26e-136</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>14:05:29</td>     <th>  Log-Likelihood:    </th> <td> -14487.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.898e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1164</td>      <th>  BIC:               </th> <td>2.900e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.805e+05</td> <td> 1728.549</td> <td>  104.432</td> <td> 0.000</td> <td> 1.77e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.114e+04</td> <td> 1634.120</td> <td>    6.815</td> <td> 0.000</td> <td> 7930.811</td> <td> 1.43e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 4089.5066</td> <td> 1677.167</td> <td>    2.438</td> <td> 0.015</td> <td>  798.898</td> <td> 7380.116</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>  4.63e+04</td> <td> 1783.141</td> <td>   25.968</td> <td> 0.000</td> <td> 4.28e+04</td> <td> 4.98e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>326.351</td> <th>  Durbin-Watson:     </th> <td>   2.019</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2200.071</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.113</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 9.345</td>  <th>  Cond. No.          </th> <td>    1.25</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.417\n","Model:                            OLS   Adj. R-squared:                  0.416\n","Method:                 Least Squares   F-statistic:                     277.7\n","Date:                Fri, 29 Nov 2019   Prob (F-statistic):          6.26e-136\n","Time:                        14:05:29   Log-Likelihood:                -14487.\n","No. Observations:                1168   AIC:                         2.898e+04\n","Df Residuals:                    1164   BIC:                         2.900e+04\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.805e+05   1728.549    104.432      0.000    1.77e+05    1.84e+05\n","x1          1.114e+04   1634.120      6.815      0.000    7930.811    1.43e+04\n","x2          4089.5066   1677.167      2.438      0.015     798.898    7380.116\n","x3           4.63e+04   1783.141     25.968      0.000    4.28e+04    4.98e+04\n","==============================================================================\n","Omnibus:                      326.351   Durbin-Watson:                   2.019\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2200.071\n","Skew:                           1.113   Prob(JB):                         0.00\n","Kurtosis:                       9.345   Cond. No.                         1.25\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"82JvbYIzn6zH","colab_type":"text"},"source":["Analisando os valores acima, vimos que todas as features possuem um P-value significativo, ou seja, dentro do intervalo definido (SL = .05) .Portanto, deixamos elas e escolhemos outra feature para incrementar no modelo conforme o processo de Forward Elimination. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6x6W76baoIbx"},"source":["Calculando os coeficientes com a adição da 4ª feature (*OverallCond* - Condição Geral):\n"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"72819efb-46c8-4c28-e593-29ca059e1197","executionInfo":{"status":"ok","timestamp":1575036329695,"user_tz":180,"elapsed":1950,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"XM_T6jHGoIby","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Selecionando apenas as features de indice 0-const, 1-LotArea, 2-PoolArea, 3-GarageArea, 4-OverallCond\n","X_opt = X_train[:, [0,1,2,3,4]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.417</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.415</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   208.2</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Fri, 29 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.06e-134</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>14:05:29</td>     <th>  Log-Likelihood:    </th> <td> -14487.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.898e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th> <td>2.901e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.805e+05</td> <td> 1729.280</td> <td>  104.384</td> <td> 0.000</td> <td> 1.77e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 1.112e+04</td> <td> 1635.325</td> <td>    6.800</td> <td> 0.000</td> <td> 7911.844</td> <td> 1.43e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 4088.4437</td> <td> 1677.789</td> <td>    2.437</td> <td> 0.015</td> <td>  796.611</td> <td> 7380.276</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td>  4.64e+04</td> <td> 1802.016</td> <td>   25.749</td> <td> 0.000</td> <td> 4.29e+04</td> <td> 4.99e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td>  652.2132</td> <td> 1741.565</td> <td>    0.374</td> <td> 0.708</td> <td>-2764.748</td> <td> 4069.175</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>326.932</td> <th>  Durbin-Watson:     </th> <td>   2.020</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2206.916</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.114</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 9.354</td>  <th>  Cond. No.          </th> <td>    1.31</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.417\n","Model:                            OLS   Adj. R-squared:                  0.415\n","Method:                 Least Squares   F-statistic:                     208.2\n","Date:                Fri, 29 Nov 2019   Prob (F-statistic):          1.06e-134\n","Time:                        14:05:29   Log-Likelihood:                -14487.\n","No. Observations:                1168   AIC:                         2.898e+04\n","Df Residuals:                    1163   BIC:                         2.901e+04\n","Df Model:                           4                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.805e+05   1729.280    104.384      0.000    1.77e+05    1.84e+05\n","x1          1.112e+04   1635.325      6.800      0.000    7911.844    1.43e+04\n","x2          4088.4437   1677.789      2.437      0.015     796.611    7380.276\n","x3           4.64e+04   1802.016     25.749      0.000    4.29e+04    4.99e+04\n","x4           652.2132   1741.565      0.374      0.708   -2764.748    4069.175\n","==============================================================================\n","Omnibus:                      326.932   Durbin-Watson:                   2.020\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2206.916\n","Skew:                           1.114   Prob(JB):                         0.00\n","Kurtosis:                       9.354   Cond. No.                         1.31\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"My7j1OM6oIb2"},"source":["Analisando os valores acima, vimos que toda a feature *OverallCond* (Condição Geral da Casa) não possui um P-value significativo, ou seja, dentro do intervalo definido (SL = .05), pois a mesma possui um valor de 0.708. Portanto, deixamos elas e escolhemos outra feature para incrementar no modelo conforme o processo de Forward Elimination. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yY35BqcboJzW"},"source":["**Final:** Analisando os valores acima, vimos que todas as features possuem um P-value significativo, ou seja, dentro do intervalo definido (SL = .05) .Portanto, não iremos adicionar ela ao modelo final, visto que ela não impacta de maneira positiva ao modelo. Finalmente, esse ciclo se repete até que todas as features sejam analisadas."]},{"cell_type":"markdown","metadata":{"id":"fnB83_TCtkqm","colab_type":"text"},"source":["Treinando o modelo com o conjunto de treinamento.\n","\n","**Obs:** A feature de índice 0 é uma constante (1) que foi somente criada para análise do processo de seleção. Portanto, não foi inserida no treinamento do modelo devido. "]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"480ce810-de43-4b9f-df62-8f671560828b","executionInfo":{"status":"ok","timestamp":1575036329696,"user_tz":180,"elapsed":1945,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"kip24crWlW2M","colab":{"base_uri":"https://localhost:8080/"}},"source":["regressor = LinearRegression()\n","regressor.fit(X_test[:, [1,2,3]], y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_THRIQTQlW2Q"},"source":["Analisando o novo score do modelo com a métrica r2"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"88fb839c-d721-4ba6-d576-bee85d534fc6","executionInfo":{"status":"ok","timestamp":1575036329696,"user_tz":180,"elapsed":1939,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"6O_eCKVglW2R","colab":{"base_uri":"https://localhost:8080/"}},"source":["regressor.score(X_test[:, [1,2,3]], y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.41858756810845454"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qrsyDtcnmac8"},"source":["##  Backward Elimination"]},{"cell_type":"markdown","metadata":{"id":"yJGIyJR2lHGg","colab_type":"text"},"source":["### Etapa de Seleção e Tratamento dos Dados"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fGfVdeTsrN7A"},"source":["Definindo as variáveis indepedentes e dependentes, normalição das features e divisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5X0V5cGvrN7C","colab":{}},"source":["X = df[df.columns[~df.columns.isin(['SalePrice'])]].values\n","y = df['SalePrice'].values.reshape(-1,1)\n","\n","# Normalização das features:\n","X = feature_scaling(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XKpYcfrgvh04"},"source":["### Realizando o Processo de Backward Elimination\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_pnkCb88rd8B"},"source":["Realizando o processo de Backward Elimination. Esse processo é realizado através de uma análise da contribuição de todas as features ao modelo final. Portanto, a cada iteração é removida uma feature que deverá ser analisada seu impacto no modelo através do *p-value*."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GxRB879vrd8D"},"source":["Primeiro, será inserido uma coluna preenchida com valores 1 no começo da matriz de feature para que seja realizado os cálculos necessários. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n85AHl_zrd8D","colab":{}},"source":["X = np.append(arr = np.ones((1460,1)).astype(int), values = X, axis =1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wkAHLwJHrd8J"},"source":["Divisão do dataset em conjunto de treinamento e testes:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aykKC8Ffrd8K","outputId":"04bee90e-204b-49e8-cf3d-caedd3519984","executionInfo":{"status":"ok","timestamp":1575121356375,"user_tz":180,"elapsed":1492,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Dividindo os dados\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","\n","X_train[1:5,:5]"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1.        , -0.26857781, -0.06869175, -0.43503222,  1.28068524],\n","       [ 1.        , -0.1743691 , -0.06869175, -2.21296298,  1.28068524],\n","       [ 1.        , -0.33241925, -0.06869175, -1.09005935,  1.28068524],\n","       [ 1.        , -0.55290771, -0.06869175, -0.77190332,  0.38174271]])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZwH7sJ-Crv74"},"source":["Analisando todas as features no modelo:"]},{"cell_type":"code","metadata":{"id":"SUUM2LlRgdSP","colab_type":"code","outputId":"92596c94-70dd-4170-d04f-9376dd17d129","executionInfo":{"status":"ok","timestamp":1575121360021,"user_tz":180,"elapsed":889,"user":{"displayName":"Baldoino Fonseca","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCDqlL9df4VYBIv0X8DI4M0GQCxRUymTHzRlFuJoA=s64","userId":"10444310980437302642"}},"colab":{"base_uri":"https://localhost:8080/","height":570}},"source":["# Importando a package.\n","import statsmodels.regression.linear_model as sm\n","\n","X_opt = X_train[:, [0,1,2,3,4,5,6,7]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.572</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.570</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   221.7</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Sat, 30 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>7.88e-209</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>13:42:39</td>     <th>  Log-Likelihood:    </th> <td> -14307.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.863e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1160</td>      <th>  BIC:               </th> <td>2.867e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.808e+05</td> <td> 1483.694</td> <td>  121.883</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 8061.6719</td> <td> 1446.960</td> <td>    5.571</td> <td> 0.000</td> <td> 5222.720</td> <td> 1.09e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 3336.4581</td> <td> 1448.058</td> <td>    2.304</td> <td> 0.021</td> <td>  495.353</td> <td> 6177.563</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 3.006e+04</td> <td> 1765.796</td> <td>   17.021</td> <td> 0.000</td> <td> 2.66e+04</td> <td> 3.35e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td> 8726.2152</td> <td> 1607.366</td> <td>    5.429</td> <td> 0.000</td> <td> 5572.546</td> <td> 1.19e+04</td>\n","</tr>\n","<tr>\n","  <th>x5</th>    <td> 2.612e+04</td> <td> 1783.040</td> <td>   14.647</td> <td> 0.000</td> <td> 2.26e+04</td> <td> 2.96e+04</td>\n","</tr>\n","<tr>\n","  <th>x6</th>    <td>  236.3377</td> <td> 1494.222</td> <td>    0.158</td> <td> 0.874</td> <td>-2695.342</td> <td> 3168.017</td>\n","</tr>\n","<tr>\n","  <th>x7</th>    <td> 2.165e+04</td> <td> 1584.915</td> <td>   13.663</td> <td> 0.000</td> <td> 1.85e+04</td> <td> 2.48e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>464.282</td> <th>  Durbin-Watson:     </th> <td>   1.997</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5052.077</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td>12.724</td>  <th>  Cond. No.          </th> <td>    2.04</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.572\n","Model:                            OLS   Adj. R-squared:                  0.570\n","Method:                 Least Squares   F-statistic:                     221.7\n","Date:                Sat, 30 Nov 2019   Prob (F-statistic):          7.88e-209\n","Time:                        13:42:39   Log-Likelihood:                -14307.\n","No. Observations:                1168   AIC:                         2.863e+04\n","Df Residuals:                    1160   BIC:                         2.867e+04\n","Df Model:                           7                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.808e+05   1483.694    121.883      0.000    1.78e+05    1.84e+05\n","x1          8061.6719   1446.960      5.571      0.000    5222.720    1.09e+04\n","x2          3336.4581   1448.058      2.304      0.021     495.353    6177.563\n","x3          3.006e+04   1765.796     17.021      0.000    2.66e+04    3.35e+04\n","x4          8726.2152   1607.366      5.429      0.000    5572.546    1.19e+04\n","x5          2.612e+04   1783.040     14.647      0.000    2.26e+04    2.96e+04\n","x6           236.3377   1494.222      0.158      0.874   -2695.342    3168.017\n","x7          2.165e+04   1584.915     13.663      0.000    1.85e+04    2.48e+04\n","==============================================================================\n","Omnibus:                      464.282   Durbin-Watson:                   1.997\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5052.077\n","Skew:                           1.521   Prob(JB):                         0.00\n","Kurtosis:                      12.724   Cond. No.                         2.04\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"0bPosa1zQmkw","colab_type":"text"},"source":["Analisando os valores acima, vimos que a feature X6 (*YrSold* - Ano de Venda) possui p-value de .874, enquanto que as outras features possui um valor abaixo do limiar (SL = .05). Portanto, tal feature deve ser retirada seguindo o processo de Backward Selection.\n","\n","**Obs: Definimos um level de significância de .05 para que as features permaneçam no modelo (SL = .05).**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bm2sbvtZQff5"},"source":["Remoção da  6ª Feature (*YrSold* - Ano de Venda):"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"f936a64e-a603-48c2-b479-4e719306f7e4","executionInfo":{"status":"ok","timestamp":1575036330065,"user_tz":180,"elapsed":2276,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"id":"KXFIOBwxQff8","colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["#Analisando todas as features, exceto 6-YrSold\n","\n","X_opt = X_train[:, [0,1,2,3,4,5,7]]\n","regressor_ols = sm.OLS(endog = y_train, exog = X_opt).fit()\n","regressor_ols.summary()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.572</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.570</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   258.8</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Fri, 29 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>4.75e-210</td>\n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>14:05:29</td>     <th>  Log-Likelihood:    </th> <td> -14307.</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.863e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  1161</td>      <th>  BIC:               </th> <td>2.866e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td> 1.808e+05</td> <td> 1483.065</td> <td>  121.935</td> <td> 0.000</td> <td> 1.78e+05</td> <td> 1.84e+05</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td> 8062.8559</td> <td> 1446.333</td> <td>    5.575</td> <td> 0.000</td> <td> 5225.137</td> <td> 1.09e+04</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td> 3320.0150</td> <td> 1443.714</td> <td>    2.300</td> <td> 0.022</td> <td>  487.434</td> <td> 6152.596</td>\n","</tr>\n","<tr>\n","  <th>x3</th>    <td> 3.005e+04</td> <td> 1764.767</td> <td>   17.028</td> <td> 0.000</td> <td> 2.66e+04</td> <td> 3.35e+04</td>\n","</tr>\n","<tr>\n","  <th>x4</th>    <td> 8732.9953</td> <td> 1606.119</td> <td>    5.437</td> <td> 0.000</td> <td> 5581.775</td> <td> 1.19e+04</td>\n","</tr>\n","<tr>\n","  <th>x5</th>    <td> 2.612e+04</td> <td> 1781.992</td> <td>   14.658</td> <td> 0.000</td> <td> 2.26e+04</td> <td> 2.96e+04</td>\n","</tr>\n","<tr>\n","  <th>x6</th>    <td> 2.165e+04</td> <td> 1584.243</td> <td>   13.668</td> <td> 0.000</td> <td> 1.85e+04</td> <td> 2.48e+04</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td>464.454</td> <th>  Durbin-Watson:     </th> <td>   1.996</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5049.657</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td> 1.522</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td>12.721</td>  <th>  Cond. No.          </th> <td>    2.04</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.572\n","Model:                            OLS   Adj. R-squared:                  0.570\n","Method:                 Least Squares   F-statistic:                     258.8\n","Date:                Fri, 29 Nov 2019   Prob (F-statistic):          4.75e-210\n","Time:                        14:05:29   Log-Likelihood:                -14307.\n","No. Observations:                1168   AIC:                         2.863e+04\n","Df Residuals:                    1161   BIC:                         2.866e+04\n","Df Model:                           6                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const       1.808e+05   1483.065    121.935      0.000    1.78e+05    1.84e+05\n","x1          8062.8559   1446.333      5.575      0.000    5225.137    1.09e+04\n","x2          3320.0150   1443.714      2.300      0.022     487.434    6152.596\n","x3          3.005e+04   1764.767     17.028      0.000    2.66e+04    3.35e+04\n","x4          8732.9953   1606.119      5.437      0.000    5581.775    1.19e+04\n","x5          2.612e+04   1781.992     14.658      0.000    2.26e+04    2.96e+04\n","x6          2.165e+04   1584.243     13.668      0.000    1.85e+04    2.48e+04\n","==============================================================================\n","Omnibus:                      464.454   Durbin-Watson:                   1.996\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5049.657\n","Skew:                           1.522   Prob(JB):                         0.00\n","Kurtosis:                      12.721   Cond. No.                         2.04\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"fg2HMnAvRdZd","colab_type":"text"},"source":["Analisando os valores acima, vimos que todas as features possuem um valor muito próximo de zero, exceto a feature X6 (*PoolArea* - Área da Piscina) que possui p-value de .022. Apesar da feature PoolArea se diferenciar das demais, ela ainda está abaixo do limiar definido (SL = .05). \n","\n","**Obs: Definimos um level de significância de .05 para que as features permaneçam no modelo (SL = .05).**"]},{"cell_type":"markdown","metadata":{"id":"E82mdQB9SGxa","colab_type":"text"},"source":["**Final:** Portanto, seguindo o processo de Backward Selection, todas as features acima devem ser mantidas no model."]},{"cell_type":"markdown","metadata":{"id":"xJp_hnTkim6o","colab_type":"text"},"source":["Treinamento do modelo com todas as features que tem um SL abaixo de .05, \n","\n","**Obs:** A feature de índice 0 é uma constante (1) que foi somente criada para análise do processo de seleção. Portanto, não foi inserida no treinamento do modelo devido. "]},{"cell_type":"code","metadata":{"id":"_q6TLZini8iZ","colab_type":"code","outputId":"5f29f3fb-5a4c-4a74-e0db-d17bf864b2ce","executionInfo":{"status":"ok","timestamp":1575036330065,"user_tz":180,"elapsed":2269,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor = LinearRegression()\n","#Treinando o modelo de Regressão com todas as features, exceto X6\n","regressor.fit(X_train[:, [1,2,3,4,5,7]], y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"z4-ETswtkaLF","colab_type":"text"},"source":["Analisando o novo score do modelo com a métrica r²:"]},{"cell_type":"code","metadata":{"id":"FGVjEh5jkaUj","colab_type":"code","outputId":"d4a28e91-1ae9-4c9c-84a5-3ec3a93223d0","executionInfo":{"status":"ok","timestamp":1575036330066,"user_tz":180,"elapsed":2264,"user":{"displayName":"Jairo Souza","photoUrl":"","userId":"04219546553145172755"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["regressor.score(X_test[:, [1,2,3,4,5,7]], y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5633529452543352"]},"metadata":{"tags":[]},"execution_count":88}]}]}